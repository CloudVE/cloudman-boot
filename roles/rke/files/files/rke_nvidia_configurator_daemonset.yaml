apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: rke-nvidia-configurator-daemonset
  namespace: gpu-operator
spec:
  selector:
    matchLabels:
      app: rke-nvidia-configurator
      app.kubernetes.io/part-of: rke2
  template:
    metadata:
      labels:
        app: rke-nvidia-configurator
        app.kubernetes.io/part-of: rke2
    spec:
      serviceAccountName: rke-nvidia-configurator-svc-account
      initContainers:
        - name: rke-nvidia-configurator-daemonset
          image: bitnami/kubectl:latest
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          command:
            - /bin/sh
            - -c
            - >
              echo Node name is $NODE_NAME &&
              export TOOLKIT_POD=$(kubectl get -n gpu-operator-resources pods -l app=nvidia-container-toolkit-daemonset --field-selector=spec.nodeName=$NODE_NAME -o=name) &&
              until kubectl logs --tail 10 -n gpu-operator-resources $TOOLKIT_POD | grep "Waiting for signal";
              do echo Waiting for toolkit to be ready;
              sleep 2;
              done;
              echo Restarting containerd with new rke2 nvidia config;
              cp /src/config.toml.tmpl /dest/config.toml.tmpl &&
              echo Restarting nvidia toolkit daemonset &&
              kubectl rollout restart -n gpu-operator-resources daemonset/nvidia-container-toolkit-daemonset &&
              echo Sleeping for 30 seconds &&
              sleep 30 &&
              echo Restarting remaining nvidia daemonsets &&
              kubectl rollout restart -n gpu-operator-resources daemonset/nvidia-dcgm-exporter &&
              kubectl rollout restart -n gpu-operator-resources daemonset/gpu-feature-discovery &&
              kubectl rollout restart -n gpu-operator-resources daemonset/nvidia-device-plugin-daemonset
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            runAsUser: 0
          volumeMounts:
          - mountPath: "/src"
            name: containerd-template
          - mountPath: "/dest"
            name: containerd-config
      containers:
        - name: pause
          image: gcr.io/google_containers/pause
          resources:
            limits:
              cpu: 20m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 10Mi
      nodeSelector:
        nvidia.com/gpu.present: "true"
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      volumes:
      - name: containerd-template
        configMap:
          name: rke-nvidia-configurator-configmap
      - name: containerd-config
        hostPath:
          path: /var/lib/rancher/rke2/agent/etc/containerd
          type: ""
